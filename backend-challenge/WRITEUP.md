# Open-Ended Questions

## 1. 
    I would first add a String field Password under each User. When creating a new user, we will store a hashed password in here through a library such as bcrypt with SHA-256 hashing. This library addresses a potential vulnerability to brute forcing as it has a slow hashing method, so each query takes longer. This would be done through the existing [POST] to '/api/users'.
    To sign in, we will first hash the password with bcrypt and then compare it with the hashed password in the database. As we hash it before sending it to the databse, if this flow or the database gets compromised, then the data will still be safe. If the passwords are the same, it will log in the user with the method below. This would use a [POST] route to '/api/login'. 
    For staying signed in, we can use the jwt library to implement JSONWebTokens, as these  allow for stateless authentication and prevent constant unecessary database calls to verify tokens by by just using the secret key to fetch the user_id and verify the token. We will store the user_id and an expiration_time in the JWT and then put that in an HTTP-only cookie, to protect against compromising it form the front-end, and give it a shorter expiration time. We can then create another JWT refresh_token which has a longer expiration time and, if this is still valid when the access_token expires, then we can refresh the access token and this to prevent the user having to constantly sign back in. This minimalizes the time the token is valid and accessible on the front-end, so it is more difficult to compromise the user.
    To sign out, we can just clear both of these cookies. This could use a [POST] route to '/api/logout'.

## 2.
    First I would like to note that I implemented this as I had additional time, so I will explain what I did. I first created a new model Comment in the database which has a body (character limit 511), id, created_at, and updated_at fields. It then stores, through foreign keys, a reference to it's User and Club ids. 
    To allow for replies to comments, I added a one-to-many relationship from Comments to itself called replies. This allows each comment to be associated with multiple comments, so I can have a chain of replies to a single comment, but each comment can only have one parent so one-to-many suffices over a many-to-many. I also added a cascade all, delete orphan to the replies relationship so deleting the parent comment will delete all child comments recursively, so no comments will be orphaned. To have reference to the parent comment, I also added a foreign key through a backref to parent_id which refers to the primary-key id of the parent Comment.
    I also made the created_at, club_id, and parent_id fields indexed to improve query time as it would be common to sort comments by creation time, search for all comments under a club, and search for all comments under a specific parent comment. I also indexed the user_id field so we can quickly determine all comments from a user and find their comments under a club if necessary.
    Each comment can be created by calling the [POST] route '/api/clubs/<club_id>/comments', which can also be used thorugh a [GET] to get all comments under a club. The comment id is be incremented automatically for each comment created. There is also a [DELETE], [POST], and [GET] to '/api/comments/<comment_id>' which can delete, modify, and get a club from a specific id.

## 3.
    The first thing I would cache is the route `/api/tags` as this changes very infrequently but is called everytime on the search page. I would also cache `/api/clubs/<int:club_id>` and `/api/tags/<int:tag_id>` as these have a lot of relationship joins with complex things that could be expensive due to the large size of the dataset. I would also cache `/api/clubs/search/<club_string>` as this is called the most frequently as users are constantly searching clubs, and this is a really big dataset.
    For Cache invalidation, I would invalidate clubs when any club is POST'd or DELETEd as this needs to be updated right away. For tags, I would do the same to prevent invalidation. I would also make the caches invalidate after some time, with the clubs searching and club data refreshing caches more frequently than other endpoints such as tags.